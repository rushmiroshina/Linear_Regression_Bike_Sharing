{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Reading and Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"day.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the columns have 730 non-null rows,there is no null columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correcting values of columns\n",
    "df['weathersit']=df.weathersit.map({1: 'Clear',2:'Mist',3:'Light Snow/Rain',4:'Heavy Snow/Rain'})\n",
    "df['season']=df.season.map({1:'spring', 2:'summer', 3:'fall', 4:'winter'})\n",
    "df['weekday']=df.weekday.map({0:'Sunday', 1:'Monday', 2:'Tuesday', 3:'Wednesday',4:'Thursday',5:'Friday',6:'Saturday'})\n",
    "df['mnth']=df.mnth.map({1:'January',2:'February',3:'March',4:'April',5:'May',6:'June',7:'July',8:'August',9:'September',10:'October',11:'November',12:'December'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analsing the Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=df[['cnt','temp','atemp','hum','windspeed']]\n",
    "sns.pairplot(df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temp and atemp have a linear relationship with cnt.And also temp and atemp are highly correlated with each other.This may result in multicolinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,3,1)\n",
    "sns.boxplot(x='yr',y='cnt',data=df)\n",
    "ax=plt.subplot(2,3,2)\n",
    "sns.boxplot(x='mnth',y='cnt',data=df)\n",
    "ax.tick_params(labelrotation=45)\n",
    "ax=plt.subplot(2,3,3)\n",
    "sns.boxplot(x='season',y='cnt',data=df)\n",
    "ax.tick_params(labelrotation=45)\n",
    "plt.subplot(2,3,4)\n",
    "sns.boxplot(x='holiday',y='cnt',data=df)\n",
    "plt.subplot(2,3,5)\n",
    "sns.boxplot(x='workingday',y='cnt',data=df)\n",
    "ax=plt.subplot(2,3,6)\n",
    "sns.boxplot(x='weekday',y='cnt',data=df)\n",
    "ax.tick_params(labelrotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working day seems to be a good predictor.With 5000 as median more than 50% of the bikes were rented during working day \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More rental were made in the year 2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median count of rentals for each weekday seems to be around 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May to October the bike rental count were in good number.Many bookings were made during that period of the year "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 32% of the bike booking were happening in fall with almost 5000 bookings as median "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('weathersit','cnt',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More bikes were rented during clear weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unwanted col\n",
    "df=df.drop(['instant','dteday','registered','casual'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy variable creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather=pd.get_dummies(df['weathersit'],drop_first=True)\n",
    "Season=pd.get_dummies(df['season'],drop_first=True)\n",
    "day=pd.get_dummies(df['weekday'],drop_first=True)\n",
    "month=pd.get_dummies(df['mnth'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df,weather,Season,day,month],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the columns for which dummy variables are created\n",
    "df=df.drop([\"weathersit\",\"season\",\"weekday\",\"mnth\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Initial Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test=train_test_split(df,train_size=0.7,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_vars=[\"temp\",\"hum\",\"windspeed\",\"cnt\",\"atemp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[scale_vars]=scaler.fit_transform(df_train[scale_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,25))\n",
    "ax=sns.heatmap(df_train.corr(),annot=True,cmap=\"Greens\")\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature seems to be more correlated with count.Plotting this heatmap will be used as a reference for building the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the data into X and y\n",
    "y_train = df_train.pop('cnt')\n",
    "X_train = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Building the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recursive feature elimination is used to automatically remove low correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe=RFE(lm,15)\n",
    "rfe=rfe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns,rfe.support_,rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe=X_train[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building the OLS Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe=sm.add_constant(X_train_rfe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=sm.OLS(y_train,X_train_rfe).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the VIF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the const column\n",
    "X_train_rfe = X_train_rfe.drop(['const'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif['Features']=X_train_rfe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]\n",
    "vif['VIF']=round(vif['VIF'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif=vif.sort_values(by='VIF',ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping December since it has high P-value among all\n",
    "X_train_new1 = X_train_rfe.drop([\"December\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe1=sm.add_constant(X_train_new1)\n",
    "lm1=sm.OLS(y_train,X_train_rfe1).fit()\n",
    "lm1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating vif for new model\n",
    "X_train_rfe1 = X_train_rfe1.drop([\"const\"], axis = 1)\n",
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train_rfe1.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_rfe1.values, i) for i in range(X_train_rfe1.shape[1])]\n",
    "vif['VIF']=round(vif['VIF'],2)\n",
    "vif=vif.sort_values(by='VIF',ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping November sincle it has high p-value and low VIF\n",
    "X_train_rfe2 = X_train_rfe1.drop([\"November\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the next model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe2=sm.add_constant(X_train_rfe2)\n",
    "lm2=sm.OLS(y_train,X_train_rfe2).fit()\n",
    "lm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating vif for new model\n",
    "X_train_rfe2 = X_train_rfe2.drop(['const'], axis=1)\n",
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train_rfe2.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_rfe2.values, i) for i in range(X_train_rfe2.shape[1])]\n",
    "vif['VIF']=round(vif['VIF'],2)\n",
    "vif=vif.sort_values(by='VIF',ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#humidity can be dropped due to high VIF\n",
    "X_train_rfe3 = X_train_rfe2.drop([\"hum\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe3=sm.add_constant(X_train_rfe3)\n",
    "lm3=sm.OLS(y_train,X_train_rfe3).fit()\n",
    "lm3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe3 = X_train_rfe3.drop(['const'], axis=1)\n",
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train_rfe3.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_rfe3.values, i) for i in range(X_train_rfe3.shape[1])]\n",
    "vif['VIF']=round(vif['VIF'],2)\n",
    "vif=vif.sort_values(by='VIF',ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#January has high P-value and low VIF so it can be dropped\n",
    "X_train_rfe4 = X_train_rfe3.drop([\"January\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe4=sm.add_constant(X_train_rfe4)\n",
    "lm4=sm.OLS(y_train,X_train_rfe4).fit()\n",
    "lm4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe4 = X_train_rfe4.drop(['const'], axis=1)\n",
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train_rfe4.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_rfe4.values, i) for i in range(X_train_rfe4.shape[1])]\n",
    "vif['VIF']=round(vif['VIF'],2)\n",
    "vif=vif.sort_values(by='VIF',ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing July since it has high p value and low p-value\n",
    "X_train_rfe5 = X_train_rfe4.drop([\"July\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe5=sm.add_constant(X_train_rfe5)\n",
    "lm5=sm.OLS(y_train,X_train_rfe5).fit()\n",
    "lm5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe5 = X_train_rfe5.drop(['const'], axis=1)\n",
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train_rfe5.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_rfe5.values, i) for i in range(X_train_rfe5.shape[1])]\n",
    "vif['VIF']=round(vif['VIF'],2)\n",
    "vif=vif.sort_values(by='VIF',ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing windspeed since it has high VIF and low correltion\n",
    "X_train_rfe6 = X_train_rfe5.drop([\"windspeed\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Model6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_rfe6=sm.add_constant(X_train_rfe6)\n",
    "lm6=sm.OLS(y_train,X_train_rfe6).fit()\n",
    "lm6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train_rfe6.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_rfe6.values, i) for i in range(X_train_rfe6.shape[1])]\n",
    "vif['VIF']=round(vif['VIF'],2)\n",
    "vif=vif.sort_values(by='VIF',ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model seems to be good now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The co-efficient values of the features are below:\n",
    "- yr\t          0.2332\n",
    "- holiday\t     -0.0991\n",
    "- temp\t          0.4896\n",
    "- LightSnow/Rain -0.2998\n",
    "- Mist\t         -0.0770\n",
    "- spring\t     -0.0648\n",
    "- summer\t      0.0523\n",
    "- winter\t      0.0957\n",
    "- September\t      0.0954"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-Statistics:\n",
    "The higher the value the good the model is.In our case it is __255.2__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P value:\n",
    "All features have p-value less than 0.005.Then the model is Statistically Significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VIF\n",
    "All VIF<5.Hence there is no multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best fit equation:\n",
    "cnt = 0.1414 + ( yr × 0.2332) - ( holiday x 0.0991) + ( temp ×0.4896) − ( LightSnow/Rain x 0.2998) - (mist x 0.0770) − (spring ×0.0648) + (summer x 0.0523) + (winter x 0.0957) + (September x 0.0954) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co-effitients interpretation:\n",
    "- __temp__ : A degree raise in temp will raise the bie rental by 0.4896\n",
    "- __holiday__ : As the number of holidays increases the bike rental decreases\n",
    "- __year__ : The bike rentals increases yearly\n",
    "- __LightSnow/Rain__ : On account of this condition the bike rentals decreases by 0.2998\n",
    "- __mist__ : Mist affects bike rentals by 0.0770\n",
    "- __summer__ :Has positive effect on rental\n",
    "- __winter__ : Has positive effect on rental\n",
    "- __spring__ : Has negative effect on rental\n",
    "- __September__ :During this month the rental is affected by a positive factor value of 0.0954"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Residual Analysis of the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the y value for training set\n",
    "y_train_pred=lm6.predict(X_train_rfe6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding error terms\n",
    "res = y_train - y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error term seems to follow a Normal Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_train,res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error terms are scattered hence they possess no relation.Seems to have constant variance (homoscedasticity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating r2 value for train data\n",
    "r2_train=r2_score(y_train,y_train_pred)\n",
    "r2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating adjusted r2 for train data\n",
    "n = X_train.shape[0]\n",
    "\n",
    "p = X_train.shape[1]\n",
    "\n",
    "adjusted_r2_train = 1-(1-r2_train)*(n-1)/(n-p-1)\n",
    "adjusted_r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Prediction and Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_vars=[\"temp\",\"hum\",\"windspeed\",\"cnt\",\"atemp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[scale_vars]=scaler.fit_transform(df_test[scale_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=df_test.pop('cnt')\n",
    "X_test=df_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe6.drop([\"const\"], axis = 1,inplace=True)\n",
    "X_test_new = X_test[X_train_rfe6.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a constant variable \n",
    "X_test_new1 = sm.add_constant(X_test_new)\n",
    "X_test_new1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting y value for test set\n",
    "y_pred = lm6.predict(X_test_new1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculatin gerror terms for test set\n",
    "res = y_test - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error term seems to follow a Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_test,res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error terms seems to be random and seems to follow homoscedasticity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating r2 value for test set\n",
    "\n",
    "r2_test=r2_score(y_test,y_pred)\n",
    "r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculating gadjusted r2 value for test set\n",
    "n = X_test.shape[0]\n",
    "\n",
    "p = X_test.shape[1]\n",
    "\n",
    "adjusted_r2_test = 1-(1-r2_test)*(n-1)/(n-p-1)\n",
    "adjusted_r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating MSE\n",
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE value is nearly 0.Hence we can assume the model to be acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __r2_score_train__ : 0.8212172937848272\n",
    "- __adj_r2_score_train__ : 0.8104158386176605\n",
    "- __r2_score_test__  : 0.8052122801477507\n",
    "- __adj_r2_score_test__  : 0.7754815229071442"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be a really good model that can very well 'Generalize' various datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights\n",
    "#### Positive Impacts:\n",
    "- The good the __Temperature__ is the more the bike rentals are\n",
    "- As the __year__ increases the bike rentals also increases\n",
    "- Bike rentals are more during __summer__ and __winter__ seasons\n",
    "- The month of __September__ has increased rentals than other months\n",
    "\n",
    "#### Negative Impacts:\n",
    "- When __holiday__ the number of bikes rented are low\n",
    "- __Snow/Rain__ may negatively affect rental\n",
    "- __Spring__ season has decreased number of rentals "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
